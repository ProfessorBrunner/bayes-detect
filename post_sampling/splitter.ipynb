{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import common\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ConfigParser import SafeConfigParser\n",
    "\n",
    "parser = SafeConfigParser()\n",
    "parser.read(\"../config.ini\")\n",
    "\n",
    "width = int(parser.get(\"Sampling\", \"width\"))\n",
    "height = int(parser.get(\"Sampling\", \"height\"))\n",
    "\n",
    "amp_min = float(parser.get(\"Sampling\", \"amp_min\"))\n",
    "amp_max = float(parser.get(\"Sampling\", \"amp_max\"))\n",
    "\n",
    "rad_min = float(parser.get(\"Sampling\", \"rad_min\"))\n",
    "rad_max = float(parser.get(\"Sampling\", \"rad_max\"))\n",
    "\n",
    "prefix = parser.get(\"Misc\", \"prefix\")\n",
    "location = parser.get(\"Misc\", \"location\")\n",
    "output_folder = location + \"/\" + prefix \n",
    "\n",
    "x,y,r,a,L = np.loadtxt(output_folder + \"/\" + prefix + \"_out_points_som.txt\", unpack=True)\n",
    "\n",
    "all_vals = np.vstack((x,y,r,a,L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniqueish_color():\n",
    "    \"\"\"There're better ways to generate unique colors, but this isn't awful.\"\"\"\n",
    "    return plt.cm.gist_ncar(np.random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bin_amt = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_dim(dim):\n",
    "    if dim == 0:\n",
    "        return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q = np.array([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_peaks(initial_bounds):\n",
    "    queue = []\n",
    "    results = [] #going to store results as (depth, [xmin, xmax, ymin, ymax])\n",
    "    \n",
    "    queue.append((0, 0, initial_bounds))#depth, dim, [[xlower, xupper],[ylower, yupper]]\n",
    "    while queue != []:\n",
    "        depth, dim, bounds = queue.pop()\n",
    "        start, stop = bounds[dim]\n",
    "        other_start, other_stop = bounds[next_dim(dim)]\n",
    "        \n",
    "        print \"bounds\"\n",
    "        print bounds\n",
    "        \n",
    "        if start == stop or other_start == other_stop:\n",
    "            continue\n",
    "        \n",
    "        dimvals = all_vals[:, dim].T\n",
    "        range_mask = np.where((dimvals >= start) & (dimvals <= stop))\n",
    "        dimvals = dimvals[range_mask]\n",
    "        lvals = all_vals[range_mask, dim].T\n",
    "        \n",
    "        _, main_mask, main_binned, main_binned_L = common.binned_max(dimvals, lvals, start, stop, bin_amt) \n",
    "        \n",
    "        if main_binned_L.shape[0] == 0:\n",
    "            #there nothing here\n",
    "            continue\n",
    "        main_smoothed = common.smooth(main_binned_L[main_mask])\n",
    "        \n",
    "        #check if there is a peak\n",
    "        median = np.median(main_smoothed)\n",
    "        peak = np.max(main_smoothed)\n",
    "        if peak < 0.999 * median:\n",
    "            continue\n",
    "        else:\n",
    "            print \"peak %f\"%peak\n",
    "            results.append((depth, bounds.flatten()))\n",
    "        \n",
    "        main_mins = common.compute_mins(main_binned[main_mask], main_smoothed)\n",
    "        main_maxes = common.compute_maxes(main_binned[main_mask], main_smoothed)\n",
    "        main_intervals = common.compute_intervals(main_mins, main_maxes)\n",
    "        main_intervals = np.floor(main_intervals).astype(\"int\")\n",
    "        \n",
    "        if main_intervals.shape[0] == 0: #no intervals to look at\n",
    "            print \"no intervals to look at\"\n",
    "            print main_smoothed\n",
    "            print main_mins, main_maxes\n",
    "            continue\n",
    "        \n",
    "        for nstart, nstop in intervals:\n",
    "        \n",
    "            other_col = all_vals[:, next_dim(dim)]\n",
    "            my_col = all_vals[:, dim]\n",
    "            my_mask = np.where((my_col >= nstart) & (my_col <= nstop))\n",
    "        \n",
    "            _, my_mask, my_binned, my_binned_L = common.binned_max(other_col[my_mask], L[my_mask], other_start, other_stop, 50) \n",
    "        \n",
    "        \n",
    "            if my_binned_L[my_mask].shape[0] == 0:\n",
    "                print \"binning failed\"\n",
    "                continue\n",
    "        \n",
    "            my_smoothed = common.smooth(my_binned_L[my_mask])\n",
    "\n",
    "            my_mins = common.compute_mins(my_binned[my_mask], my_smoothed)\n",
    "            my_maxes = common.compute_maxes(my_binned[my_mask], my_smoothed)\n",
    "            my_intervals = common.compute_intervals(my_mins, my_maxes)\n",
    "            my_intervals = np.floor(intervals).astype(\"int\")\n",
    "            \n",
    "            for my_start, my_stop in my_intervals:\n",
    "                b = np.zeros((2,2))\n",
    "                b[dim] = nstart, nstop\n",
    "                b[next_dim(dim)] = my_start, my_stop\n",
    "                queue.append((depth, next_dim(dim), b))\n",
    "                print my_start, my_stop\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounds\n",
      "[[  0 200]\n",
      " [  0 200]]\n",
      "peak 22.235704\n",
      "no intervals to look at\n",
      "[ 22.23570357  22.23570357  22.23570357  22.23570357]\n",
      "[] []\n"
     ]
    }
   ],
   "source": [
    "initial_bounds = np.array([[0, width], [0, height]])\n",
    "k = get_peaks(initial_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, array([  0, 200,   0, 200]))]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_peaks(bounds, dim, debug_plots = False):\n",
    "    start, stop = bounds[dim]\n",
    "    other_start, other_stop = bounds[next_dim(dim)]\n",
    "    \n",
    "    if start == stop:\n",
    "        return []\n",
    "    lvals = L\n",
    "    dimvals = all_vals[dim]\n",
    "    \n",
    "    _, mask, binned, binned_L = common.binned_max(dimvals, lvals, start, stop, bin_amt) \n",
    "    if binned_L[mask].shape[0] == 0:\n",
    "        return []\n",
    "    smoothed = common.smooth(binned_L[mask])\n",
    "    \n",
    "    #Check to see if there is even a possible peak\n",
    "    median = np.median(smoothed)\n",
    "    peak = np.max(smoothed)\n",
    "    print peak, median\n",
    "    if peak < 0.999 * median:\n",
    "        #some criteria\n",
    "        return []\n",
    "    \n",
    "    index = np.where(smoothed == peak)[0]\n",
    "    print index\n",
    "    print \"peak is at\"\n",
    "    print all_vals[dim, index]\n",
    "    \n",
    "    mins = common.compute_mins(binned[mask], smoothed)\n",
    "    maxes = common.compute_maxes(binned[mask], smoothed)\n",
    "    intervals = common.compute_intervals(mins, maxes)\n",
    "    intervals = np.floor(intervals).astype(\"int\")\n",
    "    \n",
    "    if intervals.shape[0] == 0:\n",
    "        return []\n",
    "    \n",
    "    new_bounds = []\n",
    "    \n",
    "    print intervals\n",
    "\n",
    "    for nstart, nstop in intervals:\n",
    "        \n",
    "        other_col = all_vals[:, next_dim(dim)].T\n",
    "        my_col = all_vals[:, dim].T\n",
    "        my_mask = np.where((my_col >= nstart) & (my_col <= nstop))\n",
    "        \n",
    "        _, my_mask, my_binned, my_binned_L = common.binned_max(other_col[my_mask], L[my_mask], other_start, other_stop, 50) \n",
    "        \n",
    "        if my_binned_L[my_mask].shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        my_smoothed = common.smooth(my_binned_L[my_mask])\n",
    "\n",
    "        my_mins = common.compute_mins(my_binned[my_mask], my_smoothed)\n",
    "        my_maxes = common.compute_maxes(my_binned[my_mask], my_smoothed)\n",
    "        my_intervals = common.compute_intervals(mins, maxes)\n",
    "        my_intervals = np.floor(intervals).astype(\"int\")\n",
    "        \n",
    "        for my_start, my_stop in my_intervals:\n",
    "            b = np.zeros((2,2))\n",
    "            b[dim] = nstart, nstop\n",
    "            b[next_dim(dim)] = my_start, my_stop\n",
    "            new_bounds.append(b)\n",
    "            \n",
    "    print \"new bounds\"\n",
    "    print new_bounds\n",
    "    return [(dim, [start, stop], get_peaks(b, next_dim(dim), debug_plots=debug_plots)) for b in new_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initial_bounds = np.array([[0, width], [0, height]])\n",
    "k = get_peaks(initial_bounds, 0, debug_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is still a work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def post_process(tree, depth=0):\n",
    "    curr_dim = tree[0]\n",
    "    dim_bounds = tree[1]\n",
    "    sub_bounds = tree[2]\n",
    "    if sub_bounds == []:\n",
    "        return []\n",
    "    my_sub_bounds = []\n",
    "    for sb in sub_bounds:\n",
    "        if sb[-1] == []:\n",
    "            my_sub_bounds.append(sb)\n",
    "    return_vals = [(depth, [dim_bounds, sb[1]]) for sb in my_sub_bounds]\n",
    "    for sub_tree in sub_bounds:\n",
    "        return_vals += post_process(sub_tree, depth+1)\n",
    "    return return_vals\n",
    "\n",
    "def get_sources(tree):\n",
    "    res = []\n",
    "    for subtree in k:\n",
    "        res += post_process(subtree)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sources(tree):\n",
    "    res = [post_process(subtree) for subtree in k]\n",
    "    res = filter(lambda x: x != [], res)\n",
    "    return_val = []\n",
    "    for part in res:\n",
    "        entry = max(part, key = lambda item: item[0])\n",
    "        deepest = entry[0]\n",
    "        \n",
    "        #now that we know the deepest, we can go and keep only the last calls\n",
    "        keep = filter(lambda item: item[0] == deepest, part)\n",
    "        return_val += keep\n",
    "    new_rv = []\n",
    "    for item in return_val:\n",
    "        t = [item[0]] +  item[1][0] + item[1][1]\n",
    "        new_rv.append(t)\n",
    "    return new_rv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = get_sources(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_sources = np.array(out)\n",
    "#depth, xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_sources.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth, xlower, xupper, ylower, yupper = temp_sources[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where((x >= xlower) & (x <= xupper) & (y >= ylower) & (y <= yupper))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sources = np.zeros((temp_sources.shape[0], 6))\n",
    "#x,y,r,a,depth, meanL\n",
    "\n",
    "for i in xrange(temp_sources.shape[0]):\n",
    "    depth, xlower, xupper, ylower, yupper = temp_sources[i]\n",
    "    mask = np.where((x >= xlower) & (x <= xupper) & (y >= ylower) & (y <= yupper))[0]\n",
    "    \n",
    "    sources[i, 0] = np.mean(x[mask])\n",
    "    sources[i, 1] = np.mean(y[mask])\n",
    "    sources[i, 2] = np.dot(r[mask], L[mask])/np.sum(L[mask])\n",
    "    sources[i, 3] = np.dot(a[mask], L[mask])/np.sum(L[mask])\n",
    "    sources[i, 4] = temp_sources[i,0]\n",
    "    sources[i, 5] = np.mean(L[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_frame = pd.DataFrame(sources, columns = [\"x\", \"y\", \"r\", \"a\", \"depth\", \"meanL\"])\n",
    "s_frame = s_frame.drop_duplicates()\n",
    "s_frame = s_frame.sort(columns=[\"meanL\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(s_frame.x, s_frame.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(s_frame.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
